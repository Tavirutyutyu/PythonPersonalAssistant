{
'main.py': 'import asyncio\nimport shutil\nimport threading\nfrom tkinter import Tk\n\nfrom GUI import Layout\nfrom assistant import Assistant\n\n\ndef main():\n    assistant = Assistant()\n    try:\n        assistant.greeting()\n        while True:\n            assistant.listen()\n    except KeyboardInterrupt:\n        print("Bye")\n    finally:\n        assistant.shutdown()\n\n\ndef test_gui():\n    window = Tk()\n    assistant = Assistant()\n    try:\n        assistant.greeting()\n        layout = Layout(window, assistant)\n        layout.place_on_grid()\n        layout.window.mainloop()\n    except Exception as error:\n        print(f"Error: {error}\\n\\nQuitting...")\n    finally:\n        assistant.shutdown()\n\ndef test_commands(command, execute_command_text: str):\n    print(command.execute(execute_command_text))\n\ndef test_command_by_voice(voice_assistant, command_manager):\n    voice_assistant.speak("What would you like to do? Browse on the internet or launch an IDE?")\n    possible_keywords = command_manager.get_possible_keywords()\n    print(f"Possible keywords: {possible_keywords}")\n    voice_input = voice_assistant.listen()\n    if voice_input:\n        voice_assistant.speak(f"You said {voice_input}")\n        command = command_manager.match(voice_input)\n        if command:\n            voice_assistant.speak(f"You choose {command.__class__.__name__}")\n            print(f"You choose {command.__class__.__name__}")\n            voice_assistant.speak("Choose an option:")\n            options = command.get_sub_option_keys()\n            print(f"Sub options: {options}")\n            for option in options:\n                voice_assistant.speak(option)\n            voice_option_input = voice_assistant.listen()\n            if voice_option_input:\n                command.execute(voice_option_input)\n\nasync def test_ai_handler(ai_handler, prompt:str):\n    response = await ai_handler.generate_response(prompt)\n    print(response)\n\ndef test_ai_manager_check_and_install():\n    assistant = Assistant()\n    ai_manager = assistant.local_ai_manager\n    print(ai_manager.check_install())\n    print(shutil.which("ollama"))\n\n\n\nif __name__ == "__main__":\n    test_gui()',
'config.py': 'import os\n\nRESOURCES_DIR = os.path.join(os.path.dirname(__file__), "resources")\nOLLAMA_MODEL = "llama3"\nOLLAMA_URL = "http://localhost:11434/api/generate"\nTTS_VOICE_SPEED = 200\nTTS_VOICE_VOLUME = 1.0\nSYSTEM_PROMPT_VOICE = (\n    "You are a voice assistant. "\n    "Speak in full, clear sentences. "\n    "Avoid using special characters, formatting like asterisks or Markdown, and code blocks. "\n    "Only include code if explicitly asked. "\n    "Respond as if you\'re speaking out loud to a human."\n)\nSYSTEM_PROMPT_CODE = (\n    "You are a coding assistant. "\n    "You will receive full projects with all of their files. "\n    "Your job is to help the debugging and prevent me creating bugs in the future by helping me to write the program correctly. "\n    "You are allowed to send code snippets with your answer."\n)\n',
'.gitignore': '.venv\n.idea\n**/__pycache__/\n*.py[cod]\n',
'requirements.txt': 'audioop-lts==0.2.1\nPyAudio==0.2.14\npyttsx3==2.98\nsetuptools==78.1.0\nSpeechRecognition==3.8.1\nstandard-aifc==3.13.0\nstandard-chunk==3.13.0\ntyping_extensions==4.13.2\nopenai~=1.74.0\nrequests~=2.32.3',
'assistant/assistant.py': 'import sys\nfrom typing import Callable\n\nfrom assistant.ai_manager import LocalAIManagerBase, AIManager\nfrom assistant.ai_model_handler import AIHandler\nfrom commands import Command\nfrom commands import CommandManager\nfrom voice import VoiceAssistant\n\n\nclass Assistant:\n    def __init__(self):\n        """\n        The general_ai_manager is responsible for choosing the correct AI manager.\n        The local_ai_manager is checking if a specific AI is installed, if not than installs one according to the operating system.\n        The local_ai_manager is also providing the ai_handler according to the installed AI.\n        The ai_handler is responsible for the communication with the AI.\n        The command_manager is providing the command to execute by a keyword.\n        The voice_assistant is responsible for the voice recognition and the text-to-speech.\n        And on the end of the init we start he local ai server.\n        """\n        self.general_ai_manager = AIManager()\n        self.local_ai_manager: LocalAIManagerBase = self.general_ai_manager.get_installed_manager()\n        self.ai_handler: AIHandler = self.local_ai_manager.get_ai_handler()\n        self.command_manager = CommandManager()\n        self.voice_assistant = VoiceAssistant()\n        self.local_ai_manager.start_server()\n\n    def greeting(self):\n        self.speak("Welcome to your personal assistant.")\n\n    def speak(self, text: str):\n        self.voice_assistant.speak(text)\n\n    def generate_ai_answer(self, voice_input: str, mode: str = "assistant", directory_path: str | None = None) -> str | None:\n        """\n        Accepts a string as an input, and it generates an AI answer.\n        :param voice_input: String to generate an AI answer for.\n        :param mode: This toggles between assistant mode and coding buddy mode.\n        :param directory_path: If we use the coding buddy mode, it will need the project directory path so it can\n        read out and send the content of the files in the given directory so the ai can provide help.\n        :return: Returns the generated AI answer or None if something went wrong.\n        """\n        return self.ai_handler.generate_response(voice_input, mode, directory_path)\n\n    def match_command(self, voice_input: str) -> Command | None:\n        """\n        Accepts a string as an input, and it checks if it contains any keywords for any commands.\n        :param voice_input: String to check for keywords.\n        """\n        if voice_input:\n            return self.command_manager.match(voice_input)\n\n    def listen(self, message_displayer: Callable[[str, str], None] | None = None) -> str | None:\n        """Listens with the microphone and returns the recognized text or returns None\n        :return text -> The recognized text or returns None:"""\n        voice_input = self.voice_assistant.listen(message_displayer)\n        return voice_input.lower().strip() if voice_input else None\n\n    def execute(self, command: Command, message_displayer: Callable[[str, str], None] | None = None) -> None:\n        """\n        Gets a command, check if it has sub options, if it has, it runs execute_complex_command method,\n        else it executes the command.\n        :param command: The command to execute.\n        :param message_displayer: The method used to display the conversation in text.\n        """\n        if command.has_sub_options:\n            self.__execute_complex_command(command, message_displayer)\n        else:\n            command.execute()\n\n    def __execute_complex_command(self, command: Command, message_displayer: Callable[[str, str], None] = None) -> None:\n        """\n        Shows the sub-options of a command, calls self.__choose_option() which will return the chosen sub options in a string,\n        than we call the self.__evaluate_sub_option_input() which will execute the command with the sub-option.\n        :param command: The command to execute.\n        :param message_displayer: The method used to display the conversation in text.\n        """\n        if message_displayer:\n            message_displayer("Assistant", "Choose an option:")\n        self.speak("Choose an option")\n        options = command.get_sub_option_keys()\n        if message_displayer:\n            message_displayer("Assistant", f"{str(options)}")\n        voice_option_input = self.__choose_option(options, message_displayer)\n        self.__evaluate_sub_option_input(command, voice_option_input, message_displayer)\n\n    def __evaluate_sub_option_input(self, command: Command, sub_option_input: str,\n                                    message_displayer: Callable[[str, str], None]) -> None:\n        """\n        Gets a command and a sub-option input.\n        Then it checks if the sub-option input is valid.\n        If it\'s valid, it executes the command.\n        :param command: Command to execute.\n        :param sub_option_input: The sub-option input to execute.\n        :param message_displayer: The method used to display the conversation in text.\n        """\n\n        if sub_option_input:\n            options = command.get_sub_option_keys()\n            if sub_option_input in options:\n                command.execute(sub_option_input)\n            else:\n                if message_displayer: message_displayer("Assistant", "This option does not exist.")\n                self.speak("This option does not exist.")\n        else:\n            if message_displayer: message_displayer("Assistant", "Could not hear you.")\n            self.speak("Could not hear you.")\n\n    def __choose_option(self, options: list[str], message_displayer: Callable[[str, str], None] | None = None) -> str | None:\n        """\n        Gets a list of sub options. Say them one-by-one.\n        Also, if provided than uses the message_displayer method to display the sub options.\n        Then it listens for a voice input and returns the chosen sub options.\n        :param options : List of sub options (strings).\n        :param message_displayer: The method used to display the conversation in text.\n        :return: Returns the chosen sub options or None.\n        """\n        for option in options:\n            self.speak(option)\n        voice_option_input = self.voice_assistant.listen(message_displayer)\n        if voice_option_input:\n            return voice_option_input.lower()\n        return None\n\n    def shutdown(self):\n        """\n        shuts down the assistant and the local ai server.\n        """\n        self.speak("Shutting down the assistant.")\n        self.speak("Good bye!")\n        self.local_ai_manager.stop_server()\n        sys.exit()\n',
'assistant/__init__.py': 'from .assistant import Assistant\nfrom .ai_model_handler import AIHandler\nimport assistant.ai_model_handler\nimport assistant.ai_manager',
'assistant/ai_manager/ollama_manager.py': 'import platform\nimport shutil\nimport subprocess\nimport time\nfrom os import setsid, killpg, getpgid\nfrom signal import SIGTERM\nfrom subprocess import Popen, DEVNULL\n\nfrom .local_ai_manager_base import LocalAIManagerBase\nfrom ..ai_model_handler import OllamaHandler\n\n\nclass OllamaManager(LocalAIManagerBase):\n    def __init__(self):\n        super().__init__(OllamaHandler())\n\n    def check_install(self):\n        return shutil.which("ollama") is not None\n\n    def install(self):\n        system = platform.system()\n        if system == "Darwin":\n            self.__install_mac()\n        elif system == "Linux":\n            self.__install_linux()\n        elif system == "Windows":\n            self.__install_windows()\n\n    def _start_server(self):\n        if self._process is None:\n            self._process = Popen(\n                ["ollama", "serve"],\n                stdout=DEVNULL,\n                stderr=DEVNULL,\n                preexec_fn=setsid,\n            )\n            time.sleep(1.5)\n\n    def stop_server(self):\n        if self._process is not None:\n            killpg(getpgid(self._process.pid), SIGTERM)\n            self._process = None\n\n\n    @staticmethod\n    def __install_linux():\n        try:\n            subprocess.run([\n                "curl", "-fsSL", "https://ollama.com/install.sh", "-o", "ollama_install.sh"\n            ], check=True)\n            subprocess.run(["chmod", "+x", "ollama_install.sh"], check=True)\n            subprocess.run(["bash", "ollama_install.sh"], check=True)\n            subprocess.run(["ollama", "pull", "llama3"], check=True)\n        except subprocess.CalledProcessError as e:\n            print(f"Failed to install Ollama: {e}")\n\n    @staticmethod\n    def __install_windows():\n        try:\n            print("Please install Ollama manually from https://ollama.com/download")\n            subprocess.run(["start", "https://ollama.com/download"], shell=True)\n        except Exception as e:\n            print(f"Failed to open browser for Windows install. Error: {e}")\n\n    @staticmethod\n    def __install_mac():\n        subprocess.run(["brew", "install", "ollama"])\n',
'assistant/ai_manager/ai_manager.py': 'from .ollama_manager import OllamaManager\nfrom .local_ai_manager_base import  LocalAIManagerBase\n\n\nclass AIManager:\n    def __init__(self):\n        self.__ai_managers = [OllamaManager()]\n        self.__installed_manager: LocalAIManagerBase = self.__check_install()\n\n    def __check_install(self):\n        manager = None\n        for ai_manager in self.__ai_managers:\n            if ai_manager.check_install():\n                manager = ai_manager\n        if manager is None:\n            manager = self.__install_default()\n        return manager\n\n    def __install_default(self):\n        manager = self.__ai_managers[0]\n        manager.install()\n        return manager\n\n    def get_installed_manager(self):\n        return self.__installed_manager\n',
'assistant/ai_manager/__init__.py': 'from .local_ai_manager_base import LocalAIManagerBase\nfrom .ollama_manager import OllamaManager\nfrom .ai_manager import AIManager',
'assistant/ai_manager/local_ai_manager_base.py': 'import subprocess\nfrom abc import ABC, abstractmethod\n\nfrom ..ai_model_handler import AIHandler\n\nclass LocalAIManagerBase(ABC):\n    def __init__(self, ai_handler:AIHandler):\n        self._ai_handler: AIHandler = ai_handler\n        self._process: subprocess.Popen | None = None\n\n    @abstractmethod\n    def check_install(self):\n        """\n        Checks if the user has local ai installed\n        """\n        pass\n\n    @abstractmethod\n    def install(self):\n        """\n        If the user don\'t have local ai installed this method will install it for and operating system.\n        """\n        pass\n\n    def start_server(self):\n        """\n        Checks if the user has local ai installed, if not than installs one and then starts the AI local server.\n        """\n        if not self.check_install():\n            self.install()\n        self._start_server()\n\n    @abstractmethod\n    def _start_server(self):\n        """\n        This method starts the AI local server.\n        """\n        pass\n\n    @abstractmethod\n    def stop_server(self):\n        """\n        This method stops the AI local server.\n        :return:\n        """\n        pass\n\n    def get_ai_handler(self) -> AIHandler:\n        return self._ai_handler\n',
'assistant/coding_buddy/coding_buddy.py': 'from assistant.coding_buddy import ProjectScanner\nfrom assistant.coding_buddy.call_graph_builder import CallGraphBuilder\nfrom assistant.coding_buddy.file_collector import FileCollector\n\n\nclass CodingBuddy:\n    def __init__(self):\n        self.project_scanner: ProjectScanner = ProjectScanner()\n        self.call_graph_builder: CallGraphBuilder = CallGraphBuilder()\n        self.file_collector: FileCollector = FileCollector()\n        self.files = None\n        self.graph = None\n        self.necessary_files = None\n\n    def get_project_files(self, folder_path) -> dict[str, str]:\n        self.project_scanner.scan(folder_path)\n        project_files = self.project_scanner.get_project_files()\n        self.files = project_files\n        return project_files\n\n    def get_call_graph(self, project_files):\n        call_graph = self.call_graph_builder.build(project_files)\n        self.graph = call_graph\n        return call_graph\n\n    def get_necessary_file_names(self, call_graph, entry_point) -> list[str]:\n        necessary_files = self.file_collector.get_needed_files(call_graph, entry_point)\n        self.necessary_files = necessary_files\n        return list(necessary_files)\n',
'assistant/coding_buddy/project_scanner.py': 'import os\n\nfrom .call_graph_builder import CallGraphBuilder\n\n\nclass ProjectScanner:\n    def __init__(self):\n        self.__excluded_dirs = {"__pycache__", ".git", ".venv", "node_modules", ".idea", ".vscode"}\n        self.__project_files= {}\n        self.__root_directory = None\n        self.call_graph_builder: CallGraphBuilder | None = None\n\n    def scan(self, root_directory: str) -> dict[str, str]:\n        """Scan the project directory and read all non-binary files, skipping excluded dirs."""\n        if root_directory != self.__root_directory:\n            self.__root_directory = root_directory\n        for dirpath, dirnames, filenames in os.walk(self.__root_directory):\n            # Filter out excluded directories\n            dirnames[:] = [d for d in dirnames if d not in self.__excluded_dirs]\n\n            for file in filenames:\n                rel_dir = os.path.relpath(dirpath, self.__root_directory)\n                rel_path = os.path.join(rel_dir, file) if rel_dir != "." else file\n                abs_path = os.path.join(dirpath, file)\n\n                try:\n                    with open(abs_path, "r", encoding="utf-8") as f:\n                        content = f.read()\n                        self.__project_files[rel_path] = content\n                except (UnicodeDecodeError, FileNotFoundError):\n                    continue  # Skip binary or problematic files\n        return self.__project_files\n\n    def get_structure(self, root_directory: str) -> str:\n        """Return a string representing the structure of the project."""\n        if root_directory != self.__root_directory:\n            self.__root_directory = root_directory\n        lines = [os.path.basename(self.__root_directory) + "/"]\n        for dirpath, dirnames, filenames in os.walk(self.__root_directory):\n            dirnames[:] = [d for d in dirnames if d not in self.__excluded_dirs]\n            level = dirpath.replace(self.__root_directory, "").count(os.sep)\n            indent = "    " * level\n            rel_dir = os.path.relpath(dirpath, self.__root_directory)\n\n            if rel_dir != ".":\n                lines.append(f"{indent}â””â”€â”€ {os.path.basename(dirpath)}/")\n                indent += "    "\n\n            for f in sorted(filenames):\n                lines.append(f"{indent}â””â”€â”€ {f}")\n        return "\\n".join(lines)\n\n    def build_call_graph(self):\n        if self.__project_files:\n            self.call_graph_builder = CallGraphBuilder()\n            call_graph = self.call_graph_builder.build(self.__project_files)\n            return call_graph\n\n    def format_file_structure_for_ai(self) -> str:\n        output = f"Project Structure:\\n{self.get_structure(self.__root_directory)}\\n\\n"\n        for filename in self.__project_files:\n            content = self.__project_files[filename]\n            output += f"File: {filename}\\n{\'-\' * 60}\\n{content}\\n{\'-\' * 60}\\n"\n        return output\n\n    def get_project_files(self) -> dict[str, str]:\n        """Return a dictionary mapping files to their contents."""\n        return self.__project_files\n    \n    def scan_project_and_format(self, root_directory: str) -> str:\n        self.scan(root_directory)\n        return self.format_file_structure_for_ai()\n\n\n',
'assistant/coding_buddy/file_collector.py': 'class FileCollector:\n    def __init__(self) -> None:\n        self.call_graph: CallGraph | None = None\n        self.tracer: DependencyTracer | None = None\n\n    def get_needed_files(self, graph_data: dict, entry_points: list[str]) -> set[str]:\n        self.call_graph = CallGraph(graph_data)\n        self.tracer = DependencyTracer(self.call_graph)\n        files = self.tracer.trace_from(entry_points)\n        return files\n\n    def get_needed_content(self, full_content: dict):\n        pass\n\n\nclass CallGraph:\n    def __init__(self, graph_data: dict):\n        self.graph = graph_data\n        self.func_to_file = self._build_reverse_index()\n\n    def _build_reverse_index(self):\n        mapping = {}\n        for file, functions in self.graph.items():\n            for func in functions:\n                mapping[func] = file\n        return mapping\n\n    def get_callees(self, func_name: str):\n        file = self.func_to_file.get(func_name)\n        if not file:\n            return []\n        return self.graph[file].get(func_name, [])\n\n    def get_file(self, func_name: str):\n        return self.func_to_file.get(func_name)\n\n\nclass DependencyTracer:\n    def __init__(self, call_graph: CallGraph):\n        self.call_graph = call_graph\n        self.visited = set()\n        self.required_files = set()\n\n    def trace_from(self, entry_points: list[str]) -> set[str]:\n        for entry in entry_points:\n            self._visit(entry)\n        return self.required_files\n\n    def _visit(self, func_name: str):\n        if func_name in self.visited:\n            return\n        self.visited.add(func_name)\n\n        file = self.call_graph.get_file(func_name)\n        if file:\n            self.required_files.add(file)\n\n        for callee in self.call_graph.get_callees(func_name):\n            self._visit(callee)\n',
'assistant/coding_buddy/__init__.py': 'from .project_scanner import ProjectScanner',
'assistant/coding_buddy/call_graph_builder.py': 'import ast\nfrom collections import defaultdict\n\nclass CallGraphBuilder:\n    def __init__(self):\n        self.call_graph = defaultdict(lambda: defaultdict(list))\n\n    @staticmethod\n    def build(file_contents: dict[str, str]) -> dict:\n        formatted_graph = {}\n        for file_name, content in file_contents.items():\n            try:\n                tree = ast.parse(content)\n                visitor = _QualifiedCallVisitor(content)\n                visitor.visit(tree)\n                for func, calls in visitor.calls.items():\n                    if file_name not in formatted_graph:\n                        formatted_graph[file_name] = {}\n                    formatted_graph[file_name][func] = sorted(calls)\n            except SyntaxError:\n                continue  # skip files with syntax errors\n        return formatted_graph\n\n\nclass _QualifiedCallVisitor(ast.NodeVisitor):\n    def __init__(self, content: str):\n        self.content = content\n        self.current_class = None\n        self.current_function = None\n        self.calls = defaultdict(set)\n        self.classes_in_file = set()\n\n    def visit_ClassDef(self, node):\n        """Visit each class definition and add to the set of classes"""\n        self.classes_in_file.add(node.name)\n        self.current_class = node.name  # Set the current class when inside a class\n        self.generic_visit(node)\n\n    def visit_FunctionDef(self, node):\n        prev_function = self.current_function\n        func_name = node.name\n        if self.current_class:\n            func_name = f"{self.current_class}.{func_name}"\n        self.current_function = func_name\n        self.generic_visit(node)\n        self.current_function = prev_function\n\n    def visit_AsyncFunctionDef(self, node):\n        self.visit_FunctionDef(node)\n\n    def visit_Call(self, node):\n        if self.current_function:\n            qualified_name = self._resolve_name(node.func)\n            if qualified_name:\n                first_letter = qualified_name[0]\n                if first_letter.upper() == first_letter:\n                    qualified_name = f"{qualified_name}.__init__"\n                if qualified_name == "__init__" and self.current_class:\n                    # Prepend the current class name to __init__\n                    qualified_name = f"{self.current_class}.__init__"\n                self.calls[self.current_function].add(qualified_name)\n        self.generic_visit(node)\n\n    def _resolve_name(self, node):\n        """Resolve names like Assistant.greeting or print"""\n        if isinstance(node, ast.Attribute):\n            value = self._resolve_name(node.value)\n            if value:\n                return f"{value}.{node.attr}"\n            return node.attr\n        elif isinstance(node, ast.Name):\n            return node.id\n        return None',
'assistant/ai_model_handler/ollama_handler.py': 'import requests\n\nfrom config import OLLAMA_MODEL, OLLAMA_URL, SYSTEM_PROMPT_VOICE, SYSTEM_PROMPT_CODE\nfrom .ai_handler import AIHandler\n\n\nclass OllamaHandler(AIHandler):\n    def __init__(self, model: str = OLLAMA_MODEL):\n        super().__init__(model)\n        self.url = OLLAMA_URL\n\n    def generate_response(self, prompt: str, mode: str = "assistant", root_directory: str | None = None) -> str:\n        self._message_history.append(dict(role="user", content=prompt))\n        full_prompt = self._format_prompt(self._message_history, mode, root_directory)\n\n        response = requests.post(self.url, json={\n            "model": self._model,\n            "prompt": full_prompt,\n            "stream": False\n        })\n\n        if response.status_code == 200:\n            content = response.json().get("response", "").strip()\n            self._message_history.append({"role": "assistant", "content": content})\n            return content\n        else:\n            return f"Error: {response.status_code} - {response.text}"\n\n    def _format_prompt(self, messages: list[dict], mode: str = "assistant", root_directory:str|None=None) -> str:\n        """Turn message history into a plain text prompt Ollama understands."""\n        prompt = ""\n        if mode == "assistant":\n            prompt = f"System: {SYSTEM_PROMPT_VOICE}\\n"\n        elif mode == "code":\n            prompt = f"System: {SYSTEM_PROMPT_CODE}\\n"\n            full_project_content = self.__get_full_project_structure(root_directory)\n            print(full_project_content)\n            prompt += full_project_content\n        for message in messages:\n            role = message["role"]\n            content = message["content"]\n            if role == "user":\n                prompt += f"User: {content}\\n"\n            elif role == "assistant":\n                prompt += f"Assistant: {content}\\n"\n        return prompt\n\n    def __get_full_project_structure(self, root_directory: str) -> str:\n        return self._project_scanner.scan_project_and_format(root_directory)\n',
'assistant/ai_model_handler/__init__.py': 'from .ai_handler import AIHandler\nfrom .ollama_handler import OllamaHandler',
'assistant/ai_model_handler/ai_handler.py': 'from abc import ABC, abstractmethod\n\nfrom assistant.coding_buddy import ProjectScanner\n\n\nclass AIHandler(ABC):\n    def __init__(self, model:str):\n        self._model = model\n        self._message_history = []\n        self._project_scanner = ProjectScanner()\n    @abstractmethod\n    def generate_response(self, prompt:str, mode: str = "assistant", root_directory: str | None = None) -> str:\n        pass\n',
'utils/threaded.py': 'from functools import wraps\nfrom threading import Thread\n\n\ndef threaded(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        Thread(target=func, args=args, kwargs=kwargs, daemon=True).start()\n    return wrapper', 'utils/file_loader.py': 'import json\nimport os\nfrom abc import abstractmethod, ABC\n\n\nclass FileLoader(ABC):\n    def __init__(self, directory:str):\n        self._directory = directory\n\n    @abstractmethod\n    def load(self, file_name:str, file_directory:str = None ):\n        pass\n\n\nclass JsonLoader(FileLoader):\n    def __init__(self, directory:str):\n        super().__init__(directory)\n\n    def load(self, file_name: str, file_directory: str = None ):\n        if file_directory is None:\n            file_directory = self._directory\n        file_path = os.path.join(file_directory, file_name)\n        with open(file_path, "r", encoding="utf-8") as f:\n            return json.load(f)\n', 'utils/__init__.py': 'from .file_loader import JsonLoader\nfrom .threaded import threaded', 'resources/launch_ide_command.json': '{\n  "keywords": [\n    "launch pycharm",\n    "start pycharm",\n    "open pycharm",\n    "launch intellij",\n    "start intellij",\n    "open intellij",\n    "open code editor",\n    "let\'s code",\n    "code",\n    "write code"\n  ],\n  "sub_options": {\n    "python": "pycharm",\n    "java": "idea",\n    "default": "pycharm"\n  }\n}', 'resources/hello_command.json': '{\n  "keywords": ["Whats the dilly crockodilly?"]\n}', 'resources/exit_command.json': '{\n  "keywords": ["bye", "good bye", "exit", "quit", "close assistant"]\n}', 'resources/browser_command.json': '{\n  "keywords": [\n    "browser",\n    "firefox",\n    "browse",\n    "browse on the internet",\n    "open browser"\n  ],\n  "sub_options": {\n    "google": "https://www.google.com",\n    "youtube": "https://www.youtube.com",\n    "github": "https://www.github.com",\n    "default": "https://www.duckduckgo.com",\n    "on_the_job": "https://onthejob.code.cool",\n    "journey": "https://journey.study/v2/learn"\n  }\n}', 'commands/commands.py': 'import subprocess\nimport sys\nimport webbrowser\n\nfrom commands.command_base import Command\n\n\nclass HelloCommand(Command):\n    def __init__(self):\n        super().__init__(name="hello command", file_name="hello_command.json")\n\n    def execute(self, name: str | None = None) -> str:\n        return f"Hello {name}! How can i help you?"\n\n\n\nclass BrowserCommand(Command):\n    def __init__(self):\n        super().__init__(name="browser command", file_name="browser_command.json")\n\n    def execute(self, text: str | None = None):\n        sub_options = self.get_sub_options()\n        url = sub_options.get(text.lower(), sub_options["default"])\n        webbrowser.open(url)\n\n\nclass LaunchIDECommand(Command):\n    def __init__(self):\n        super().__init__(name="code editor command", file_name="launch_ide_command.json")\n\n    def execute(self, text: str | None = None):\n        text = text.lower()\n        try:\n            sub_options = self.get_sub_options()\n            command = sub_options.get(text.lower(), sub_options["default"])\n            subprocess.Popen(command)\n        except FileNotFoundError as e:\n            print(f"IDE not found: {e}")\n        except Exception as e:\n            print(f"{e.__class__.__name__} error: {e}")\n\n\nclass ExitCommand(Command):\n    def __init__(self):\n        super().__init__(name="exit command", file_name="exit_command.json")\n\n    def execute(self, text: str | None = None):\n        sys.exit()', 'commands/command_manager.py': 'from commands.command_base import Command\nfrom commands.commands import HelloCommand, BrowserCommand, LaunchIDECommand, ExitCommand\n\n\nclass CommandManager:\n    def __init__(self):\n        self.__commands = self.initialise_commands()\n\n    @staticmethod\n    def initialise_commands():\n        all_commands = [HelloCommand(), BrowserCommand(), LaunchIDECommand(), ExitCommand()]\n        return all_commands\n\n    def match(self, match_text:str) -> Command or None:\n        for command in self.__commands:\n            if command.matches(match_text):\n                return command\n\n\n    def match_and_execute(self, match_text: str, execute_text: str):\n        command = self.match(match_text)\n        if command:\n            command.execute(execute_text)\n        else:\n            print("Command not found")\n\n    def get_possible_keywords(self):\n        keywords = []\n        for command in self.__commands:\n            keywords.append(command.get_keywords())\n\n\n', 'commands/__init__.py': 'from .command_manager import CommandManager\nfrom .command_base import Command', 'commands/command_base.py': 'from abc import ABC, abstractmethod\n\nfrom config import RESOURCES_DIR\nfrom utils import JsonLoader\nfrom utils.file_loader import FileLoader\n\n\nclass Command(ABC):\n    def __init__(self, name: str, file_name: str, directory_path: str = RESOURCES_DIR) -> None:\n        """\n        You need to provide a file that contains the command\'s keywords and if needed than sub options.\n        For example keywords: open browser, browse, firefox...\n        Sub options: Google, YouTube, GitHub...\n\n        :param file_name: The name of the file containing the command\'s keywords and sub options.\n        @type keywords: str\n        :param directory_path: The directory where the file is located.\n        @type sub_options: str\n        """\n        file_loader: FileLoader = JsonLoader(directory=directory_path)\n        command_metadata = file_loader.load(file_name)\n        self._name: str = name\n        self.__keywords: list[str] = command_metadata["keywords"]\n        self.__sub_options: dict[str, str] | None = command_metadata["sub_options"] if "sub_options" in command_metadata else None\n        self.has_sub_options: bool = True if self.__sub_options else False\n\n    def matches(self, text: str) -> bool:\n        """Check if this command should handle the given input"""\n        return any(word in text.lower() for word in self.__keywords)\n\n    @abstractmethod\n    def execute(self, text: str | None = None):\n        """Perform the command\'s action and return response text"""\n        pass\n\n    def get_sub_options(self) -> dict[str, str]:\n        return dict(self.__sub_options)\n\n    def get_sub_option_keys(self) -> list[str]:\n        return list(self.__sub_options.keys())\n\n    def get_keywords(self) -> list[str]:\n        return list(self.__keywords)\n\n    def __str__(self):\n        return self._name\n', 'GUI/chat_box.py': 'from tkinter import scrolledtext, WORD, Entry, END, Frame, Button, StringVar\nfrom typing import Callable\n\nfrom assistant import Assistant\nfrom utils import threaded\n\n\nclass AIChatBox(Frame):\n    def __init__(self, root, assistant: Assistant, master=None, **kwargs):\n        super().__init__(master, **kwargs)\n        self.assistant = assistant\n\n        self.root = root\n        self.root.title("Chat Box")\n\n        self.chat_display = scrolledtext.ScrolledText(self, wrap=WORD, state="disabled", height=20, width=50)\n        self.chat_display.grid(row=0, column=0, columnspan=2, padx=10, pady=10)\n\n        self.input_container = Frame(self)\n        self.input_container.grid(row=1, column=0, columnspan=2, padx=10, pady=(0, 10), sticky="ew")\n\n        self.user_input = Entry(self.input_container, width=40)\n        self.user_input.grid(row=0, column=0, sticky="ew")\n        self.user_input.bind("<Return>", self.__on_enter)\n\n        self.voice_mode_button_label = StringVar(value="Enter Voice Command")\n        self.voice_mode_button = Button(self.input_container, textvariable=self.voice_mode_button_label,\n                                        command=self.__voice_mode)\n        self.voice_mode_button.grid(row=0, column=1, padx=(5, 0))\n\n        self.input_container.columnconfigure(0, weight=1)\n        self._last_ai_msg_index = None\n\n        self._current_answer_future = None\n        self.cancel_request = False\n        self._last_user_prompt = None\n\n        self.__coding_buddy_mode = False\n        self.__coding_buddy_directory_path = None\n\n\n    @threaded\n    def __voice_mode(self):\n        voice_input = self.__listen()\n        self.__process_voice_input(voice_input)\n\n    def __listen(self):\n        voice_input = self.assistant.listen(self.display_message)\n        self.display_message("You", voice_input)\n        return voice_input\n\n    def __process_voice_input(self, voice_input):\n        command = self.assistant.match_command(voice_input)\n        if command:\n            if command.has_sub_options:\n                self.assistant.execute(command, self.display_message)\n            else:\n                command.execute()\n        else:\n            self.__handle_ai_response(voice_input, voice_on=True)\n\n    # Have to be public or the program crashes\n    def display_message(self, sender, message):\n        self.chat_display.configure(state="normal")\n        self.chat_display.insert(END, f"{sender}: {message}\\n")\n        self.chat_display.configure(state="disabled")\n        self.chat_display.yview(END)\n\n    def __on_enter(self, event):\n        msg = self.user_input.get().strip()\n        if msg:\n            self.display_message("You", msg)\n            self.user_input.delete(0, END)\n            self.cancel_request = False\n            self.__handle_ai_response(msg)\n\n    def __handle_ai_response(self, prompt: str, voice_on: bool = False):\n        self._last_user_prompt = prompt\n        if self.cancel_request:\n            return\n        self.__ai_response_placeholder()\n        self.__generate_ai_response(prompt, voice_on, self.__display_ai_response)\n\n    @threaded\n    def __generate_ai_response(self, prompt: str, voice_on:bool, on_done:Callable[[str, bool], None]):\n        if self.__coding_buddy_mode:\n            answer = self.assistant.generate_ai_answer(prompt, mode="code", directory_path=self.__coding_buddy_directory_path)\n        else:\n            answer = self.assistant.generate_ai_answer(prompt)\n        if self.cancel_request:\n            return\n        on_done(answer, voice_on)\n\n\n    def cancel_ai_response(self):\n        self.cancel_request = True\n        self.__clear_last_ai_response()\n\n    def correct_prompt(self):\n        self.cancel_ai_response()\n        last_prompt = self._last_user_prompt\n        if last_prompt:\n            self.__clear_last_user_prompt()\n            self.user_input.delete(0, END)\n            self.user_input.insert(0, last_prompt)\n            self.user_input.focus_set()\n\n    def toggle_coding_buddy_mode(self, folder_path):\n        if self.__coding_buddy_mode:\n            self.__coding_buddy_mode = False\n            self.__coding_buddy_directory_path = None\n        else:\n            self.__coding_buddy_mode = True\n            self.__coding_buddy_directory_path = folder_path\n\n\n\n    def __display_ai_response(self, answer: str, voice_on: bool = False):\n        if self.cancel_request:\n            return\n        self.__update_ai_response(answer)\n        if voice_on:\n            self.assistant.speak(answer)\n\n    def __clear_last_ai_response(self):\n        if self._last_ai_msg_index:\n            print("Clearing...")\n            self.chat_display.configure(state="normal")\n            self.chat_display.delete(self._last_ai_msg_index, f"{self._last_ai_msg_index} +1line")\n            self.chat_display.configure(state="disabled")\n            self.chat_display.yview(END)\n\n    def __clear_last_user_prompt(self):\n        if self._last_user_prompt:\n            self.chat_display.configure(state="normal")\n            start_index = self.chat_display.search(f"You: {self._last_user_prompt}", "1.0", END)\n            if start_index:\n                self.chat_display.delete(start_index, f"{start_index} +1line")\n            self.chat_display.configure(state="disabled")\n            self.chat_display.yview(END)\n            self._last_user_prompt = None\n\n\n    def __ai_response_placeholder(self):\n        self.chat_display.configure(state="normal")\n        index = self.chat_display.index("end-1c")\n        self.chat_display.insert(END, "Assistant: ...\\n")\n        self.chat_display.configure(state="disabled")\n        self.chat_display.yview(END)\n        self._last_ai_msg_index = index\n\n    def __update_ai_response(self, answer: str):\n        index = self._last_ai_msg_index\n        self.chat_display.configure(state="normal")\n        self.chat_display.delete(index, f"{index} +1line")\n        self.chat_display.insert(index, f"Assistant: {answer}\\n")\n        self.chat_display.configure(state="disabled")\n        self.chat_display.yview(END)\n', 'GUI/layout.py': 'import sys\nfrom tkinter import Button, filedialog, simpledialog\n\nfrom GUI.chat_box import AIChatBox\nfrom assistant import Assistant\nfrom assistant.coding_buddy.coding_buddy import CodingBuddy\n\n\nclass Layout:\n    def __init__(self, window, assistant: Assistant):\n        self.window = window\n        self.chat_box = AIChatBox(window, assistant)\n        self.chat_box.display_message("Assistant", "Welcome!")\n        self.correct_prompt_button = Button(window, text="Correct Prompt", command=self.correct_prompt)\n        self.stop_ai_answer_generation_button = Button(window, text="Stop AI Answer Generation",\n                                                       command=self.stop_ai_answer)\n        self.exit_button = Button(window, text="Exit", command=self.exit)\n        self.coding_buddy_button = Button(window, text="Coding Buddy Mode", command=self.coding_buddy_mode)\n        # Test Button\n        self.test_call_graph_button = Button(window, text="Test Call Graph", command=self.test_call_graph)\n\n    def exit(self):\n        self.window.destroy()\n        sys.exit(0)\n\n    def test_call_graph(self):\n        coding_buddy = CodingBuddy()\n        folder_path = filedialog.askdirectory()\n        files = coding_buddy.get_project_files(folder_path)\n        print(files)\n        graph = coding_buddy.get_call_graph(files)\n        entry_points = simpledialog.askstring(title="Entry Point", prompt="Enter the entry point function (e.g., main or Assistant.generate_ai_answer):", parent=self.window)\n        required_files = coding_buddy.get_necessary_file_names(graph, [entry_points])\n        print("Required files: " + str(required_files))\n\n    def place_on_grid(self):\n        self.chat_box.grid(column=0, row=0, rowspan=5)\n        self.correct_prompt_button.grid(column=1, row=0)\n        self.stop_ai_answer_generation_button.grid(column=1, row=1)\n        self.coding_buddy_button.grid(column=1, row=2)\n        self.test_call_graph_button.grid(column=1, row=3)\n        self.exit_button.grid(column=1, row=4)\n\n    def coding_buddy_mode(self):\n        folder_path = filedialog.askdirectory()\n        if folder_path:\n            self.chat_box.toggle_coding_buddy_mode(folder_path)\n\n    def remove_from_grid(self):\n        self.chat_box.grid_forget()\n        self.correct_prompt_button.grid_forget()\n        self.stop_ai_answer_generation_button.grid_forget()\n        self.exit_button.grid_forget()\n\n    def stop_ai_answer(self):\n        self.chat_box.cancel_ai_response()\n\n    def correct_prompt(self):\n        self.chat_box.correct_prompt()\n', 'GUI/__init__.py': 'from .layout import Layout', 'voice/voice_assistant.py': 'from typing import Callable\n\nfrom config import TTS_VOICE_SPEED, TTS_VOICE_VOLUME\nfrom voice.listener import Listener\nfrom voice.text_to_speech_handler import TextToSpeechBase\nfrom voice.text_to_speech_manager import TextToSpeechManager\n\n\nclass VoiceAssistant:\n    def __init__(self, language="en-US"):\n        self.language = language\n        self.__tts_manager = TextToSpeechManager()\n        self.__tts_engine: TextToSpeechBase = self.__tts_manager.get_tts_model()\n        self.listener = Listener()\n        self.set_voice_properties()\n\n    def set_voice_properties(self, rate:int=TTS_VOICE_SPEED, volume:float=TTS_VOICE_VOLUME) -> None:\n        """\n        Sets the speach rate and volume.\n        @:param rate: Speech rate.\n        @:type rate: int\n        @:param volume: Speech volume.\n        @:type volume: float\n        """\n        self.__tts_engine.set_property(\'rate\', rate)\n        self.__tts_engine.set_property(\'volume\', volume)\n\n    def listen(self, message_displayer: Callable[[str, str], None] | None = None) -> str or None:\n        """\n        Listens for speach with the microphone.\n        Returns the recognised text or returns None and speaks the problem.\n        :return text -> The recognized text or returns None:\n        """\n        return self.listener.listen(self.__tts_engine, message_displayer)\n\n    def speak(self, text:str) -> None:\n        """\n        Speaks the given text with the given TTS engine.\n        :param text: Text to speak.\n        """\n        try:\n            self.__tts_engine.say(text)\n            self.__tts_engine.run_and_wait()\n        except Exception as e:\n            print(f"Error in speech synthesis\\t|\\t{e}")', 'voice/listener.py': 'from typing import Callable\n\nimport speech_recognition as sr\nfrom speech_recognition import WaitTimeoutError, UnknownValueError, RequestError\n\nfrom voice.text_to_speech_handler import TextToSpeechBase\n\n\nclass Listener:\n    def __init__(self, noise_adjusting_time: int = 2, listen_timeout: int = 5, phrase_time_limit: int | None = None, language: str = "en-US") -> None:\n        self.__recognizer = sr.Recognizer()\n        self.__microphone = sr.Microphone()\n        self.__noise_adjusting_time = noise_adjusting_time\n        self.__listen_timeout = listen_timeout\n        self.__phrase_time_limit = phrase_time_limit\n        self.__language = language\n\n    def listen(self, speaker: TextToSpeechBase, message_displayer: Callable[[str, str], None] | None = None) -> str or None:\n        with self.__microphone as source:\n            print("Adjusting to ambient noise")\n            if message_displayer: message_displayer("System", "Adjusting to ambient noise")\n            self.__recognizer.adjust_for_ambient_noise(source, duration=self.__noise_adjusting_time)\n            try:\n                print("Listening...")\n                if message_displayer: message_displayer("System", "Listening...")\n                audio = self.__recognizer.listen(source, timeout=self.__listen_timeout, phrase_time_limit=self.__phrase_time_limit)\n                if audio.frame_data:\n                    print("Audio detected")\n                    return self.__recognizer.recognize_google(audio, language=self.__language)\n                else:\n                    print("No audio detected")\n                    return None\n            except WaitTimeoutError:\n                print("â¸ Timeout: No speech detected. Stopping...")\n                speaker.speak("Timeout. No speech detected. Stopping...")\n                return None\n            except UnknownValueError:\n                print("ðŸ¤· I couldnâ€™t understand what you said.")\n                speaker.speak("I couldn\'t understand what you said.")\n                return None\n            except RequestError as e:\n                print(f"âŒ Google API error: {e}")\n                speaker.speak("Google API error. Please try again later.")\n                return None\n', 'voice/__init__.py': 'from .voice_assistant import VoiceAssistant\nfrom .listener import Listener\nfrom .text_to_speech_handler import TextToSpeechBase\nfrom .text_to_speech_handler import FestivalTTS\nfrom .text_to_speech_manager import FestivalManager\nfrom .text_to_speech_manager import TTSManagerBase\n', 'voice/text_to_speech_handler/festival_tts.py': 'import subprocess\n\nfrom voice.text_to_speech_handler.text_to_speech_base import TextToSpeechBase\n\nclass FestivalTTS(TextToSpeechBase):\n    def __init__(self):\n        self._rate = 1.0\n        self._volume = 1.0\n        self._buffer = ""\n\n    def set_property(self, name: str, value) -> None:\n        if name == "rate":\n            self._rate = max(0.5, min(2.0, 200 / value))\n        elif name == "volume":\n            self._volume = max(0.1, min(2.0, value))\n        else:\n            print(f"Property \'{name}\' not supported by FestivalTTS")\n\n    def say(self, text: str) -> None:\n        self._buffer += text + "\\n"\n\n    def run_and_wait(self) -> None:\n        if not self._buffer:\n            return\n\n        commands = f"""\n(Parameter.set \'Duration_Stretch {self._rate})\n(set! duffint_params `((volume {self._volume})))\n(SayText "{self._buffer.strip()}")\n        """\n\n        try:\n            subprocess.run([\'festival\', \'--pipe\'], input=commands, text=True, check=True)\n        except subprocess.CalledProcessError as e:\n            print(f"Error in speech synthesis: {e}")\n\n        self._buffer = ""\n\n    def speak(self, text: str) -> None:\n        self.say(text)\n        self.run_and_wait()\n\n', 'voice/text_to_speech_handler/text_to_speech_base.py': 'from abc import ABC, abstractmethod\n\n\nclass TextToSpeechBase(ABC):\n    @abstractmethod\n    def speak(self, text: str) -> None:\n        pass\n\n    @abstractmethod\n    def set_property(self, name: str, value) -> None:\n        pass\n\n    @abstractmethod\n    def say(self, text: str) -> None:\n        pass\n\n    @abstractmethod\n    def run_and_wait(self) -> None:\n        pass\n', 'voice/text_to_speech_handler/__init__.py': 'from .festival_tts import FestivalTTS\nfrom .text_to_speech_base import TextToSpeechBase', 'voice/text_to_speech_manager/tts_manager_base.py': 'from abc import ABC, abstractmethod\n\nfrom voice.text_to_speech_handler import TextToSpeechBase\n\n\nclass TTSManagerBase(ABC):\n    def __init__(self, tts_model:TextToSpeechBase):\n        self._tts_model: TextToSpeechBase = tts_model\n\n    @abstractmethod\n    def check_install(self) -> bool:\n        pass\n\n    @abstractmethod\n    def install(self):\n        pass\n\n    def get_tts_model(self) -> TextToSpeechBase:\n        return self._tts_model', 'voice/text_to_speech_manager/__init__.py': 'from .tts_manager_base import TTSManagerBase\nfrom .festival_manager import FestivalManager\nfrom .tts_manager import TextToSpeechManager', 'voice/text_to_speech_manager/tts_manager.py': 'from voice.text_to_speech_handler import TextToSpeechBase\nfrom voice.text_to_speech_manager import FestivalManager\nfrom voice.text_to_speech_manager import TTSManagerBase\n\n\nclass TextToSpeechManager:\n    def __init__(self):\n        self.__tts_managers = [FestivalManager()]\n        self.__installed_manager: TTSManagerBase = self.__check_install()\n\n    def __check_install(self) -> TTSManagerBase:\n        manager = None\n        for tts_manager in self.__tts_managers:\n            if tts_manager.check_install():\n                manager = tts_manager\n        if manager is None:\n            manager = self.__install_default()\n        return manager\n\n    def __install_default(self) -> TTSManagerBase:\n        manager = self.__tts_managers[0]\n        manager.install()\n        return manager\n\n    def get_tts_model(self) -> TextToSpeechBase:\n        if self.__installed_manager:\n            return self.__installed_manager.get_tts_model()\n        else:\n            manager = self.__install_default()\n            return manager.get_tts_model()', 'voice/text_to_speech_manager/festival_manager.py': 'import platform\nimport shutil\nimport subprocess\nfrom voice.text_to_speech_manager import TTSManagerBase\nfrom voice.text_to_speech_handler import FestivalTTS\n\nclass FestivalManager(TTSManagerBase):\n    def __init__(self):\n        super().__init__(FestivalTTS())\n\n    def check_install(self) -> bool:\n        return shutil.which("festival") is not None\n\n    def install(self):\n        system = platform.system()\n        if system == "Linux":\n            self.__install_linux()\n        elif system == "Darwin":\n            self.__install_mac()\n        elif system == "Windows":\n            self.__install_windows()\n        else:\n            print("Unsupported OS. Please install Festival manually.")\n\n    @staticmethod\n    def __install_linux():\n        if shutil.which("apt"):\n            subprocess.run(["sudo", "apt", "update"])\n            subprocess.run(["sudo", "apt", "install", "-y", "festival"])\n        elif shutil.which("dnf"):\n            subprocess.run(["sudo", "dnf", "install", "-y", "festival"])\n        elif shutil.which("zypper"):\n            subprocess.run(["sudo", "zypper", "install", "-y", "festival"])\n        elif shutil.which("pacman"):\n            subprocess.run(["sudo", "pacman", "-Sy", "--noconfirm", "festival"])\n        else:\n            print("Linux package manager not recognized. Install Festival manually.")\n\n    @staticmethod\n    def __install_mac():\n        if shutil.which("brew"):\n            subprocess.run(["brew", "install", "festival"])\n        else:\n            print("Homebrew is not installed. Please install it and rerun.")\n\n    @staticmethod\n    def __install_windows():\n        print("Festival is not officially supported on Windows.")\n        print("Consider using another TTS engine like pyttsx3 or install WSL (Linux on Windows) to use Festival.")\n'}
